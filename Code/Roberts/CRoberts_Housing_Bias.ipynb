{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#Ensure Python can find the Code directory\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "activity_year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "census_tract",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "derived_race",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "action_taken",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "loan_amount",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "property_value",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "income",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "interest_rate",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tract_minority_population_percent",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tract_to_msa_income_percentage",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "denial_reason-1",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "covenant_count",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "was_approved",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "covenant_density",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "county",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "c6acfd3e-c1ba-4769-a672-7fe7229ac286",
       "rows": [
        [
         "0",
         "2023",
         "27037060737.0",
         "Race Not Available",
         "6",
         "185000.0",
         "195000",
         null,
         "6.125",
         "40.37",
         "73.48",
         "10",
         "0.0",
         "False",
         null,
         "Hennepin"
        ],
        [
         "1",
         "2023",
         "27141030504.0",
         "Race Not Available",
         "6",
         "375000.0",
         "385000",
         null,
         "6.625",
         "10.64",
         "121.26",
         "10",
         "0.0",
         "False",
         null,
         "Hennepin"
        ],
        [
         "2",
         "2023",
         "27023950400.0",
         "Race Not Available",
         "6",
         "105000.0",
         "105000",
         null,
         "6.125",
         "8.92",
         "90.13",
         "10",
         "0.0",
         "False",
         null,
         "Hennepin"
        ],
        [
         "3",
         "2023",
         "27171100101.0",
         "Race Not Available",
         "6",
         "285000.0",
         "285000",
         null,
         "6.75",
         "13.27",
         "104.37",
         "10",
         "0.0",
         "False",
         null,
         "Hennepin"
        ],
        [
         "4",
         "2023",
         "27159480100.0",
         "Race Not Available",
         "6",
         "175000.0",
         "175000",
         null,
         "6.875",
         "5.87",
         "82.22",
         "10",
         "0.0",
         "False",
         null,
         "Hennepin"
        ]
       ],
       "shape": {
        "columns": 15,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity_year</th>\n",
       "      <th>census_tract</th>\n",
       "      <th>derived_race</th>\n",
       "      <th>action_taken</th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>property_value</th>\n",
       "      <th>income</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>tract_minority_population_percent</th>\n",
       "      <th>tract_to_msa_income_percentage</th>\n",
       "      <th>denial_reason-1</th>\n",
       "      <th>covenant_count</th>\n",
       "      <th>was_approved</th>\n",
       "      <th>covenant_density</th>\n",
       "      <th>county</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>2.703706e+10</td>\n",
       "      <td>Race Not Available</td>\n",
       "      <td>6</td>\n",
       "      <td>185000.0</td>\n",
       "      <td>195000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.125</td>\n",
       "      <td>40.37</td>\n",
       "      <td>73.48</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hennepin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>2.714103e+10</td>\n",
       "      <td>Race Not Available</td>\n",
       "      <td>6</td>\n",
       "      <td>375000.0</td>\n",
       "      <td>385000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.625</td>\n",
       "      <td>10.64</td>\n",
       "      <td>121.26</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hennepin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>2.702395e+10</td>\n",
       "      <td>Race Not Available</td>\n",
       "      <td>6</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>105000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.125</td>\n",
       "      <td>8.92</td>\n",
       "      <td>90.13</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hennepin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>2.717110e+10</td>\n",
       "      <td>Race Not Available</td>\n",
       "      <td>6</td>\n",
       "      <td>285000.0</td>\n",
       "      <td>285000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.75</td>\n",
       "      <td>13.27</td>\n",
       "      <td>104.37</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hennepin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023</td>\n",
       "      <td>2.715948e+10</td>\n",
       "      <td>Race Not Available</td>\n",
       "      <td>6</td>\n",
       "      <td>175000.0</td>\n",
       "      <td>175000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.875</td>\n",
       "      <td>5.87</td>\n",
       "      <td>82.22</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hennepin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   activity_year  census_tract        derived_race  action_taken  loan_amount  \\\n",
       "0           2023  2.703706e+10  Race Not Available             6     185000.0   \n",
       "1           2023  2.714103e+10  Race Not Available             6     375000.0   \n",
       "2           2023  2.702395e+10  Race Not Available             6     105000.0   \n",
       "3           2023  2.717110e+10  Race Not Available             6     285000.0   \n",
       "4           2023  2.715948e+10  Race Not Available             6     175000.0   \n",
       "\n",
       "  property_value  income interest_rate  tract_minority_population_percent  \\\n",
       "0         195000     NaN         6.125                              40.37   \n",
       "1         385000     NaN         6.625                              10.64   \n",
       "2         105000     NaN         6.125                               8.92   \n",
       "3         285000     NaN          6.75                              13.27   \n",
       "4         175000     NaN         6.875                               5.87   \n",
       "\n",
       "   tract_to_msa_income_percentage  denial_reason-1  covenant_count  \\\n",
       "0                           73.48               10             0.0   \n",
       "1                          121.26               10             0.0   \n",
       "2                           90.13               10             0.0   \n",
       "3                          104.37               10             0.0   \n",
       "4                           82.22               10             0.0   \n",
       "\n",
       "   was_approved covenant_density    county  \n",
       "0         False              NaN  Hennepin  \n",
       "1         False              NaN  Hennepin  \n",
       "2         False              NaN  Hennepin  \n",
       "3         False              NaN  Hennepin  \n",
       "4         False              NaN  Hennepin  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use functions and packages\n",
    "df = utils.load_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 201862 entries, 0 to 201861\n",
      "Data columns (total 15 columns):\n",
      " #   Column                             Non-Null Count   Dtype  \n",
      "---  ------                             --------------   -----  \n",
      " 0   activity_year                      201862 non-null  int64  \n",
      " 1   census_tract                       199830 non-null  float64\n",
      " 2   derived_race                       201862 non-null  object \n",
      " 3   action_taken                       201862 non-null  int64  \n",
      " 4   loan_amount                        201862 non-null  float64\n",
      " 5   property_value                     177186 non-null  object \n",
      " 6   income                             176400 non-null  float64\n",
      " 7   interest_rate                      166454 non-null  object \n",
      " 8   tract_minority_population_percent  201862 non-null  float64\n",
      " 9   tract_to_msa_income_percentage     201862 non-null  float64\n",
      " 10  denial_reason-1                    201862 non-null  int64  \n",
      " 11  covenant_count                     201862 non-null  float64\n",
      " 12  was_approved                       201862 non-null  bool   \n",
      " 13  covenant_density                   15420 non-null   object \n",
      " 14  county                             201862 non-null  object \n",
      "dtypes: bool(1), float64(6), int64(3), object(5)\n",
      "memory usage: 21.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For each column, show the number of missing values for each value of census_tract as a table\n",
    "missing = df.groupby('census_tract').apply(lambda x: x.isnull().sum(), include_groups = False)\n",
    "missing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill the property_value, income, and interest_rate columns with census_tract means\n",
    "df['property_value'] = df['property_value'].fillna(df.groupby('census_tract')['property_value'].transform('mean'))\n",
    "df['income'] = df['income'].fillna(df.groupby('census_tract')['income'].transform('mean'))\n",
    "df['interest_rate'] = df['interest_rate'].fillna(df.groupby('census_tract')['interest_rate'].transform('mean'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, RepeatedKFold, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report,f1_score, precision_score, recall_score\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dummy variables for the categorical columns\n",
    "categorical_features = ['derived_race', 'action_taken', 'denial_reason-1']\n",
    "df_clean = pd.get_dummies(df, columns=categorical_features, drop_first=True, dtype='int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop additional columns\n",
    "df_clean.drop(columns=['covenant_density', 'census_tract','activity_year', 'tract_minority_population_percent', 'tract_to_msa_income_percentage', 'covenant_count'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impute missing values\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_clean_imputed = imputer.fit_transform(df_clean)\n",
    "df_clean_imputed = pd.DataFrame(df_clean_imputed, columns=df_clean.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into features and target\n",
    "X = df_clean_imputed.drop('was_approved', axis=1)\n",
    "y = df_clean_imputed['was_approved']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictive Modeling - Based on Hennepin County dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize and fit the Logistic Regression model\n",
    "lr = LogisticRegression(solver='liblinear', max_iter=1000)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model accuracy on the training and test sets\n",
    "y_train_pred = lr.predict(X_train)\n",
    "y_test_pred = lr.predict(X_test)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Train accuracy: {train_accuracy:.3f}\")\n",
    "print(f\"Test accuracy: {test_accuracy:.3f}\")\n",
    "\n",
    "#Display the confusion matrix for the training set\n",
    "print('Confusion Matrix - Training Set')\n",
    "print(confusion_matrix(y_train_pred, y_train))\n",
    "print('Confusion Matrix - Test Set')\n",
    "print(confusion_matrix(y_test_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the residuals\n",
    "y_pred_lr = lr.predict(X_test).astype(int)\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(range(len(y_pred_lr)), y_test - y_pred_lr)\n",
    "plt.axhline(0, color='black', lw=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the cross-validation method\n",
    "cv_method = RepeatedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "#Define the search grid and number of neighbors\n",
    "search_grid = dict()\n",
    "search_grid['n_neighbors'] = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19]\n",
    "#Execute the grid search\n",
    "best_score = 0\n",
    "#Minimum improvement threshold\n",
    "tolerance = 0.001\n",
    "#Number of iterations to wait before stopping  \n",
    "patience = 3  \n",
    "wait = 0\n",
    "best_n = None\n",
    "best_model = None\n",
    "for n in search_grid['n_neighbors']:\n",
    "    model = KNeighborsClassifier(n_neighbors=n)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=cv_method, scoring='accuracy', n_jobs=-1)\n",
    "    mean_score = np.mean(scores)\n",
    "\n",
    "    if mean_score > best_score + tolerance:\n",
    "        best_score = mean_score\n",
    "        best_n = n\n",
    "        wait = 0  # Reset patience counter\n",
    "    else:\n",
    "        wait += 1\n",
    "\n",
    "    if wait >= patience:\n",
    "        print(f\"Early stopping triggered. Best n_neighbors: {best_n} with accuracy {best_score:.4f}\")\n",
    "        break\n",
    "\n",
    "print(f\"Final best n_neighbors: {best_n} with accuracy {best_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the KNN model with the best parameters\n",
    "k = best_n\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "knn.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model accuracy on the training and test sets\n",
    "y_train_pred = knn.predict(X_train)\n",
    "y_test_pred = knn.predict(X_test)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Train accuracy: {train_accuracy:.3f}\")\n",
    "print(f\"Test accuracy: {test_accuracy:.3f}\")\n",
    "\n",
    "#Display the confusion matrix for the training set\n",
    "print('Confusion Matrix - Training Set')\n",
    "print(confusion_matrix(y_train_pred, y_train))\n",
    "print('Confusion Matrix - Test Set')\n",
    "print(confusion_matrix(y_test_pred, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVCrbf = make_pipeline(StandardScaler(), SVC(kernel='rbf',max_iter=-1))\n",
    "SVCrbf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model accuracy on the training and test sets\n",
    "y_train_pred = SVCrbf.predict(X_train)\n",
    "y_test_pred = SVCrbf.predict(X_test)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Train accuracy: {train_accuracy:.3f}\")\n",
    "print(f\"Test accuracy: {test_accuracy:.3f}\")\n",
    "\n",
    "#Display the confusion matrix for the training set\n",
    "print('Confusion Matrix - Training Set')\n",
    "print(confusion_matrix(y_train_pred, y_train))\n",
    "print('Confusion Matrix - Test Set')\n",
    "print(confusion_matrix(y_test_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize and fit the Decision Tree model\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "#Evaluate the model accuracy on the training and test sets\n",
    "y_train_pred = dt.predict(X_train)\n",
    "y_test_pred = dt.predict(X_test)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Train accuracy: {train_accuracy:.3f}\")\n",
    "print(f\"Test accuracy: {test_accuracy:.3f}\")\n",
    "\n",
    "#Display the confusion matrix for the training set\n",
    "print('Confusion Matrix - Training Set')\n",
    "print(confusion_matrix(y_train_pred, y_train))\n",
    "print('Confusion Matrix - Test Set')\n",
    "print(confusion_matrix(y_test_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis and Comparison of Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictive Modeling - Applying the models to Ramsey County dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
