{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install geopandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A notebook for the Data Ethics Coruse\n",
    "\n",
    "Assembled by John Wallin with the help of Claude 3.5, GPT-4o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Housing Discrimination and Algorithmic Bias: A Data Ethics Project\n",
    "\n",
    "## Background and Context\n",
    "\n",
    "### Historical Housing Discrimination\n",
    "Racial covenants were legal clauses in property deeds that prohibited sale or occupancy by non-white people. These discriminatory practices, along with redlining and other systematic forms of housing discrimination, shaped the demographic and economic patterns we see in our cities today. While racial covenants were made illegal by the Fair Housing Act of 1968, their effects continue to influence modern housing patterns, property values, and wealth distribution.\n",
    "\n",
    "The Mapping Prejudice Project at the University of Minnesota has documented over 30,000 racial covenants in ramsey County. These covenants, implemented between 1910 and 1955, created lasting patterns of segregation and economic disparity that persist in modern data.\n",
    "\n",
    "### Modern Mortgage Lending\n",
    "Today, most mortgage lending decisions involve algorithmic systems that assess credit risk and determine loan approval. While these systems don't explicitly consider race, they may perpetuate historical biases through:\n",
    "- Property valuations influenced by historical segregation\n",
    "- Neighborhood characteristics shaped by past discrimination\n",
    "- Economic factors that reflect generational wealth disparities\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This project examines the relationship between historical housing discrimination and modern lending patterns, focusing on two distinct types of bias:\n",
    "\n",
    "1. **Data Bias**: How historical discrimination is embedded in modern data\n",
    "   - Property values in areas with/without historical covenants\n",
    "   - Neighborhood demographic and economic characteristics\n",
    "   - Patterns of generational wealth and investment\n",
    "\n",
    "2. **Algorithmic Bias**: How modern lending systems might perpetuate discrimination\n",
    "   - Mortgage approval rates and terms\n",
    "   - Risk assessment criteria\n",
    "   - The use of potentially biased proxy variables\n",
    "\n",
    "## Data Sources\n",
    "\n",
    "### Primary Dataset (Provided)\n",
    "You will receive a preprocessed dataset combining:\n",
    "- Covenant density by census tract\n",
    "- Property values\n",
    "- Modern mortgage lending data\n",
    "- Census demographic information\n",
    "\n",
    "### Original Data Sources (For Reference and Extension Work)\n",
    "1. **Mapping Prejudice Project**\n",
    "   - URL: https://mappingprejudice.umn.edu/\n",
    "   - Contains: Historical covenant data for ramsey County\n",
    "   - Format: GIS data showing covenant locations and details\n",
    "\n",
    "2. **Census TIGER/LINE Files**\n",
    "   - URL: https://www.census.gov/cgi-bin/geo/shapefiles/index.php?year=2024&layergroup=Census+Tracts\n",
    "   - Contains: Census tract boundaries\n",
    "   - Format: Geographic shapefiles\n",
    "\n",
    "3. **HMDA Data Browser**\n",
    "   - URL: https://ffiec.cfpb.gov/data-browser/data/2023?category=states&items=MN\n",
    "   - Contains: Modern mortgage lending data\n",
    "   - Format: CSV files with lending information\n",
    "\n",
    "## Project Components\n",
    "\n",
    "### 1. Initial Analysis (50%)\n",
    "Using the provided dataset:\n",
    "- Analyze relationships between covenant density and property values\n",
    "- Examine modern mortgage approval patterns\n",
    "- Identify potential proxy variables for historical discrimination\n",
    "- Compare lending patterns in historically covenanted vs. non-covenanted areas\n",
    "\n",
    "### 2. Bias Investigation (30%)\n",
    "Clearly distinguish between and analyze:\n",
    "- **Data Bias**: Document how historical discrimination appears in modern data\n",
    "  - Property value disparities\n",
    "  - Neighborhood characteristics\n",
    "  - Economic indicators\n",
    "- **Algorithmic Bias**: Examine how lending algorithms might perpetuate discrimination\n",
    "  - Approval rate patterns\n",
    "  - Loan term differences\n",
    "  - Risk assessment criteria\n",
    "\n",
    "### 3. Ramsey County Extension (20%)\n",
    "Extend the analysis to Ramsey County:\n",
    "1. Gather data from the provided sources\n",
    "2. Adapt the analysis methods from ramsey County\n",
    "3. Compare patterns between counties\n",
    "4. Document challenges and limitations\n",
    "\n",
    "## Deliverables\n",
    "\n",
    "### GitHub Repository\n",
    "- Analysis code and documentation\n",
    "- Data processing scripts\n",
    "- Meeting summaries (AI-assisted)\n",
    "- Visualization code\n",
    "- README explaining repository organization\n",
    "\n",
    "### Final Report (5 pages)\n",
    "1. Introduction and Historical Context\n",
    "2. Methodology\n",
    "3. Findings\n",
    "   - Data bias analysis\n",
    "   - Algorithmic bias analysis\n",
    "   - County comparison\n",
    "4. Discussion\n",
    "   - Implications for modern lending\n",
    "   - Proposed mitigation strategies\n",
    "5. Limitations and Future Work\n",
    "\n",
    "### Presentation (15 minutes)\n",
    "- Historical context\n",
    "- Methodology overview\n",
    "- Key findings\n",
    "- Visualizations\n",
    "- Recommendations\n",
    "\n",
    "## Technical Resources\n",
    "- You will receive access to:\n",
    "  - Preprocessed dataset for ramsey County\n",
    "  - Python notebook showing data preparation steps\n",
    "  - Sample visualization code\n",
    "\n",
    "## Evaluation\n",
    "Grading will follow the provided rubrics, with special emphasis on:\n",
    "- Clear distinction between data and algorithmic bias\n",
    "- Quality of technical analysis\n",
    "- Depth of historical understanding\n",
    "- Effectiveness of communication\n",
    "- Success in Ramsey County extension\n",
    "\n",
    "## Tips for Success\n",
    "- Start with the provided dataset to understand basic patterns\n",
    "- Document all assumptions and methodological choices\n",
    "- Clearly separate findings related to data bias vs. algorithmic bias\n",
    "- Consider ethical implications throughout your analysis\n",
    "- Plan the Ramsey County extension early - data collection takes time\n",
    "\n",
    "\n",
    "# Housing Discrimination and Algorithmic Bias: A Data Ethics Project\n",
    "\n",
    "[Previous sections remain the same through \"Technical Resources\"]\n",
    "\n",
    "## Project Steps\n",
    "\n",
    "### Step 1: Set Up Project Infrastructure\n",
    "\n",
    "1. **Create the GitHub Repository**\n",
    "   - One group member creates a repository named `DATA6550-Housing-Bias`\n",
    "   - Required directory structure:\n",
    "     ```\n",
    "     databias_report.docx\n",
    "     readme.md\n",
    "     Code/\n",
    "       Lastname1/\n",
    "       Lastname2/\n",
    "       Lastname3/\n",
    "       Lastname4/\n",
    "     Data/\n",
    "       ramsey_analysis.csv\n",
    "       [Additional datasets]\n",
    "     Collaboration/\n",
    "       WeekA.docx\n",
    "       WeekB.docx\n",
    "     Analysis/\n",
    "       [Graphics and intermediate results]\n",
    "     ```\n",
    "   - Share repository access with all group members\n",
    "   - Add the instructor as a collaborator\n",
    "\n",
    "2. **Set Up Shared Document**\n",
    "   - Create shared Word document in OneDrive named `databias_report.docx`\n",
    "   - Enable \"Track Changes\" under the Review tab\n",
    "   - Share with all team members and instructor\n",
    "   - Add link to document in D2L Dropbox\n",
    "\n",
    "### Step 2: Create Group Communication Plan\n",
    "\n",
    "1. Choose a communication platform (D2L forums, Teams, Zoom, etc.)\n",
    "2. Invite all group members and instructor to the platform\n",
    "3. Establish regular check-in schedule\n",
    "4. Document communication protocols in repository README\n",
    "\n",
    "### Step 3: Initial Data Exploration\n",
    "\n",
    "1. Download and examine the provided ramsey County dataset\n",
    "2. Review documentation of data sources:\n",
    "   - Mapping Prejudice Project\n",
    "   - Census TIGER/LINE files\n",
    "   - HMDA Data Browser\n",
    "3. Document initial observations in shared report\n",
    "\n",
    "### Step 4: Divide and Execute Tasks\n",
    "\n",
    "1. Assign specific analysis responsibilities:\n",
    "   - Historical context research\n",
    "   - Data bias analysis\n",
    "   - Algorithmic bias investigation\n",
    "   - Visualization development\n",
    "2. Each member must contribute their own code to their personal directory\n",
    "3. Regular code reviews and integration discussions\n",
    "\n",
    "### Step 5: Document Discussions\n",
    "\n",
    "1. After each group meeting, create AI-generated summary including:\n",
    "   - Key decisions and insights\n",
    "   - Task assignments and deadlines\n",
    "   - Challenges and solutions\n",
    "2. Save summaries as WeekA.docx and WeekB.docx in Collaboration folder\n",
    "\n",
    "### Step 6: Conduct Primary Analysis\n",
    "\n",
    "1. Analyze Hennepin County data:\n",
    "   - Property value patterns\n",
    "   - Lending disparities\n",
    "   - Demographic correlations\n",
    "2. Document methodology and findings\n",
    "3. Create visualizations\n",
    "4. Regular repository updates\n",
    "\n",
    "### Step 7: Ramsey County Extension\n",
    "\n",
    "1. Collect required datasets\n",
    "2. Apply analysis methodology\n",
    "3. Compare results with ramsey County\n",
    "4. Document challenges and limitations\n",
    "\n",
    "### Step 8: Complete Final Report\n",
    "\n",
    "1. Compile findings in shared Word document\n",
    "2. Include sections on:\n",
    "   - Historical context\n",
    "   - Methodology\n",
    "   - Results\n",
    "   - Comparative analysis\n",
    "   - Recommendations\n",
    "3. Ensure all members contribute with tracked changes\n",
    "\n",
    "### Step 9: Submit Deliverables\n",
    "\n",
    "1. **GitHub Repository**\n",
    "   - Complete code base\n",
    "   - Documentation\n",
    "   - Analysis results\n",
    "   - Meeting summaries\n",
    "\n",
    "2. **D2L Group Dropbox**\n",
    "   - Final report PDF\n",
    "   - Collaboration summaries\n",
    "   - Repository URL\n",
    "   - Presentation slides\n",
    "\n",
    "3. **Individual Dropbox**\n",
    "   - Personal contribution summary\n",
    "   - Lessons learned\n",
    "   - Reflection on findings\n",
    "\n",
    "### Step 10: Present Findings\n",
    "\n",
    "1. Prepare 15-minute presentation\n",
    "2. Include:\n",
    "   - Historical context\n",
    "   - Methodology overview\n",
    "   - Key findings\n",
    "   - Visualizations\n",
    "   - Recommendations\n",
    "3. Be prepared for Q&A\n",
    "\n",
    "[Previous sections on Evaluation remain the same]\n",
    "\n",
    "## Important Notes\n",
    "\n",
    "- Submit only one repository URL and report per group\n",
    "- Maintain regular commits to show consistent progress\n",
    "- Document all data sources and methodological decisions\n",
    "- Clearly distinguish between data bias and algorithmic bias findings\n",
    "- Start Ramsey County data collection early\n",
    "- Use course forums or office hours for technical support\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this block we filter the Minnesota tract data from the Census database\n",
    "\n",
    "[https://www.census.gov/cgi-bin/geo/shapefiles/index.php?year=2024&layergroup=Census+Tracts](https://www.census.gov/cgi-bin/geo/shapefiles/index.php?year=2024&layergroup=Census+Tracts)\n",
    "\n",
    "The county code is hard coded in this block, so you will need to change it for other counties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Read the full state file\n",
    "mn_tracts = gpd.read_file('../Data/tl_2024_27_tract.zip')\n",
    "os.getcwd(), \"../..\", \n",
    "# Filter for Ramsey County (FIPS code 123)\n",
    "ramsey_tracts = mn_tracts[mn_tracts['COUNTYFP'] == '123']\n",
    "\n",
    "# Save just ramsey County if you want\n",
    "ramsey_tracts.to_file('ramsey_tracts.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mortgage data from 2023\n",
    "\n",
    "We now reading the mortgage data for Minnesota in 2023.\n",
    "\n",
    "[https://ffiec.cfpb.gov/data-browser/data/2023?category=states&items=MN](https://ffiec.cfpb.gov/data-browser/data/2023?category=states&items=MN)\n",
    "\n",
    "Data is available back to 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chanc\\AppData\\Local\\Temp\\ipykernel_9288\\2219985529.py:1: DtypeWarning: Columns (22,23,24,26,27,28,29,30,31,32,33,38,44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  mortgage_data = pd.read_csv('../Data/state_MN.csv')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['activity_year', 'lei', 'derived_msa-md', 'state_code', 'county_code',\n",
       "       'census_tract', 'conforming_loan_limit', 'derived_loan_product_type',\n",
       "       'derived_dwelling_category', 'derived_ethnicity', 'derived_race',\n",
       "       'derived_sex', 'action_taken', 'purchaser_type', 'preapproval',\n",
       "       'loan_type', 'loan_purpose', 'lien_status', 'reverse_mortgage',\n",
       "       'open-end_line_of_credit', 'business_or_commercial_purpose',\n",
       "       'loan_amount', 'loan_to_value_ratio', 'interest_rate', 'rate_spread',\n",
       "       'hoepa_status', 'total_loan_costs', 'total_points_and_fees',\n",
       "       'origination_charges', 'discount_points', 'lender_credits', 'loan_term',\n",
       "       'prepayment_penalty_term', 'intro_rate_period', 'negative_amortization',\n",
       "       'interest_only_payment', 'balloon_payment',\n",
       "       'other_nonamortizing_features', 'property_value', 'construction_method',\n",
       "       'occupancy_type', 'manufactured_home_secured_property_type',\n",
       "       'manufactured_home_land_property_interest', 'total_units',\n",
       "       'multifamily_affordable_units', 'income', 'debt_to_income_ratio',\n",
       "       'applicant_credit_score_type', 'co-applicant_credit_score_type',\n",
       "       'applicant_ethnicity-1', 'applicant_ethnicity-2',\n",
       "       'applicant_ethnicity-3', 'applicant_ethnicity-4',\n",
       "       'applicant_ethnicity-5', 'co-applicant_ethnicity-1',\n",
       "       'co-applicant_ethnicity-2', 'co-applicant_ethnicity-3',\n",
       "       'co-applicant_ethnicity-4', 'co-applicant_ethnicity-5',\n",
       "       'applicant_ethnicity_observed', 'co-applicant_ethnicity_observed',\n",
       "       'applicant_race-1', 'applicant_race-2', 'applicant_race-3',\n",
       "       'applicant_race-4', 'applicant_race-5', 'co-applicant_race-1',\n",
       "       'co-applicant_race-2', 'co-applicant_race-3', 'co-applicant_race-4',\n",
       "       'co-applicant_race-5', 'applicant_race_observed',\n",
       "       'co-applicant_race_observed', 'applicant_sex', 'co-applicant_sex',\n",
       "       'applicant_sex_observed', 'co-applicant_sex_observed', 'applicant_age',\n",
       "       'co-applicant_age', 'applicant_age_above_62',\n",
       "       'co-applicant_age_above_62', 'submission_of_application',\n",
       "       'initially_payable_to_institution', 'aus-1', 'aus-2', 'aus-3', 'aus-4',\n",
       "       'aus-5', 'denial_reason-1', 'denial_reason-2', 'denial_reason-3',\n",
       "       'denial_reason-4', 'tract_population',\n",
       "       'tract_minority_population_percent',\n",
       "       'ffiec_msa_md_median_family_income', 'tract_to_msa_income_percentage',\n",
       "       'tract_owner_occupied_units', 'tract_one_to_four_family_homes',\n",
       "       'tract_median_age_of_housing_units'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mortgage_data = pd.read_csv('../Data/state_MN.csv')\n",
    "mheaders = mortgage_data.columns\n",
    "mheaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(174738, 99)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data set size\n",
    "mortgage_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will filter the loans to only be mortgages.\n",
    "\n",
    "[https://ffiec.cfpb.gov/documentation/publications/loan-level-datasets/lar-data-fields](https://ffiec.cfpb.gov/documentation/publications/loan-level-datasets/lar-data-fields)\n",
    "\n",
    "This is loan_purpose == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter by loan_purpose = 1 (home purchase)\n",
    "mortgage_data = mortgage_data[mortgage_data['loan_purpose'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['db_id', 'workflow', 'cnty_name', 'cnty_fips', 'doc_num', 'deed_year',\n",
       "       'deed_date', 'exec_date', 'cov_text', 'seller', 'buyer', 'street_add',\n",
       "       'city', 'state', 'zip_code', 'add_cov', 'block_cov', 'lot_cov',\n",
       "       'cnty_pin', 'add_mod', 'block_mod', 'lot_mod', 'ph_dsc_mod',\n",
       "       'join_strgs', 'geocd_addr', 'geocd_dist', 'cov_type', 'match_type',\n",
       "       'manual_cx', 'dt_updated', 'zn_subj_id', 'zn_dt_ret', 'image_ids',\n",
       "       'med_score', 'plat_dbid', 'subd_dbid'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covenent = pd.read_csv('../Data/Ramsey_County_Racial_Covenants_Table.csv')\n",
    "cheaders = covenent.columns\n",
    "cheaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We need to make our data sets a bit more manageable before merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['FID', 'Racial_Res', 'Date_Deed', 'X', 'Y'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m covenant_slim \u001b[38;5;241m=\u001b[39m covenent[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRacial_Res\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate_Deed\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[0;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['FID', 'Racial_Res', 'Date_Deed', 'X', 'Y'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "covenant_slim = covenent[['FID', 'Racial_Res', 'Date_Deed', 'X', 'Y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mortgage_slim = mortgage_data[[\n",
    "    'activity_year',\n",
    "    'census_tract',\n",
    "    'derived_race',\n",
    "    'action_taken',\n",
    "    'loan_amount',\n",
    "    'property_value',\n",
    "    'income',\n",
    "    'interest_rate',\n",
    "    'tract_minority_population_percent',\n",
    "    'tract_to_msa_income_percentage',\n",
    "    'denial_reason-1'\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the two data sets\n",
    "\n",
    "Merging the two datasets is tricky because this is geographic data.  One data set uses Lat and Long.  The other is set up to use census data tracts.  To put this together, we need to convert Lat and Long into UTM coordinates and determine what is inside the tract boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original covenant points: 24119\n",
      "\n",
      "Transformed coordinate ranges:\n",
      "X range: 446281.946653618 to 483902.6287368457\n",
      "Y range: 4960740.396902054 to 5002300.463783714\n",
      "\n",
      "Tract bounds:\n",
      "X range: -93.768385 to -93.177218\n",
      "Y range: 44.785106 to 45.246618\n",
      "\n",
      "Points that matched to tracts: 24119\n",
      "Points with null tract assignments: 24119\n",
      "\n",
      "Tract Summary:\n",
      "Number of tracts with covenants: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jwallin\\AppData\\Local\\Temp\\ipykernel_7176\\204365392.py:23: UserWarning: CRS mismatch between the CRS of left geometries and the CRS of right geometries.\n",
      "Use `to_crs()` to reproject one of the input geometries to match the CRS of the other.\n",
      "\n",
      "Left CRS: EPSG:26915\n",
      "Right CRS: EPSG:4269\n",
      "\n",
      "  covenants_with_tracts = gpd.sjoin(covenant_gdf, hennepin_tracts, how='left', predicate='within')\n"
     ]
    }
   ],
   "source": [
    "# Convert covenant data to GeoDataFrame with correct initial CRS\n",
    "geometry = [Point(xy) for xy in zip(covenant_slim['X'], covenant_slim['Y'])]\n",
    "covenant_gdf = gpd.GeoDataFrame(covenant_slim, geometry=geometry)\n",
    "covenant_gdf.set_crs(epsg=4326, inplace=True)  # WGS84 decimal degrees\n",
    "\n",
    "print(\"Original covenant points:\", len(covenant_gdf))\n",
    "\n",
    "# Transform to match the tracts CRS (UTM Zone 15N)\n",
    "covenant_gdf = covenant_gdf.to_crs(epsg=26915)\n",
    "\n",
    "# Quick check of transformed coordinates\n",
    "print(\"\\nTransformed coordinate ranges:\")\n",
    "print(\"X range:\", covenant_gdf.geometry.x.min(), \"to\", covenant_gdf.geometry.x.max())\n",
    "print(\"Y range:\", covenant_gdf.geometry.y.min(), \"to\", covenant_gdf.geometry.y.max())\n",
    "\n",
    "# Verify these points fall within tract bounds\n",
    "tract_bounds = ramsey_tracts.total_bounds\n",
    "print(\"\\nTract bounds:\")\n",
    "print(\"X range:\", tract_bounds[0], \"to\", tract_bounds[2])\n",
    "print(\"Y range:\", tract_bounds[1], \"to\", tract_bounds[3])\n",
    "\n",
    "# Perform spatial join with transformed coordinates\n",
    "covenants_with_tracts = gpd.sjoin(covenant_gdf, ramsey_tracts, how='left', predicate='within')\n",
    "\n",
    "# See how many points matched to tracts\n",
    "print(\"\\nPoints that matched to tracts:\", len(covenants_with_tracts))\n",
    "print(\"Points with null tract assignments:\", covenants_with_tracts['TRACTCE'].isna().sum())\n",
    "\n",
    "# Count covenants per tract\n",
    "covenants_per_tract = covenants_with_tracts.dropna(subset=['TRACTCE']).groupby('TRACTCE').size().reset_index(name='covenant_count')\n",
    "\n",
    "print(\"\\nTract Summary:\")\n",
    "print(\"Number of tracts with covenants:\", len(covenants_per_tract))\n",
    "if len(covenants_per_tract) > 0:\n",
    "    print(\"\\nCovenant counts per tract:\")\n",
    "    print(covenants_per_tract['covenant_count'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After cleaning:\n",
      "0    27037060737\n",
      "2    27141030504\n",
      "3    27023950400\n",
      "4    27171100101\n",
      "5    27159480100\n",
      "Name: census_tract, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def format_census_tract(value):\n",
    "    try:\n",
    "        # First convert to string to handle any type\n",
    "        tract_str = str(value)\n",
    "        # Remove any decimal points and trailing zeros\n",
    "        tract_str = tract_str.split('.')[0]\n",
    "        return tract_str\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing value: {value}, Type: {type(value)}\")\n",
    "        raise e\n",
    "\n",
    "# Create a clean copy and try the conversion\n",
    "mortgage_clean = mortgage_slim.copy()\n",
    "mortgage_clean['census_tract'] = mortgage_clean['census_tract'].astype(str)\n",
    "mortgage_clean['census_tract'] = mortgage_clean['census_tract'].apply(format_census_tract)\n",
    "\n",
    "# Let's see what we got\n",
    "print(\"\\nAfter cleaning:\")\n",
    "print(mortgage_clean['census_tract'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mortgage data examples:\n",
      "0    27037060737\n",
      "2    27141030504\n",
      "3    27023950400\n",
      "4    27171100101\n",
      "5    27159480100\n",
      "Name: census_tract, dtype: object\n",
      "\n",
      "Covenant data examples:\n",
      "Series([], Name: census_tract, dtype: object)\n",
      "\n",
      "Merge Results:\n",
      "Total mortgage applications: 100931\n",
      "Applications in tracts with covenants: 0\n",
      "Unique tracts with covenants: 0\n",
      "\n",
      "Approval Rates:\n",
      "Tracts with no covenants: 0.6646619968097017\n",
      "Tracts with covenants: nan\n"
     ]
    }
   ],
   "source": [
    "# Clean mortgage data - first ensure we have strings\n",
    "mortgage_clean = mortgage_slim.copy()\n",
    "mortgage_clean['census_tract'] = mortgage_clean['census_tract'].astype(str)\n",
    "mortgage_clean['census_tract'] = mortgage_clean['census_tract'].str.replace('.0', '')\n",
    "\n",
    "# Clean mortgage data - first ensure we have strings\n",
    "mortgage_clean = mortgage_slim.copy()\n",
    "mortgage_clean['census_tract'] = mortgage_clean['census_tract'].astype(str)\n",
    "mortgage_clean['census_tract'] = mortgage_clean['census_tract'].str.replace('.0', '')\n",
    "\n",
    "\n",
    "\n",
    "# First format the covenant census tract IDs\n",
    "covenants_with_tracts['census_tract'] = (\n",
    "    covenants_with_tracts['STATEFP'] + \n",
    "    covenants_with_tracts['COUNTYFP'] + \n",
    "    covenants_with_tracts['TRACTCE']\n",
    ")\n",
    "\n",
    "# Create the per-tract counts\n",
    "covenants_per_tract = covenants_with_tracts.groupby('census_tract').size().reset_index(name='covenant_count')\n",
    "\n",
    "# Clean the mortgage data\n",
    "mortgage_clean = mortgage_slim.copy()\n",
    "mortgage_clean['census_tract'] = mortgage_clean['census_tract'].astype(str).str.replace('.0', '')\n",
    "\n",
    "# Verify the formats match\n",
    "print(\"Mortgage data examples:\")\n",
    "print(mortgage_clean['census_tract'].head())\n",
    "print(\"\\nCovenant data examples:\")\n",
    "print(covenants_per_tract['census_tract'].head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Merge the datasets\n",
    "combined_data = mortgage_clean.merge(\n",
    "    covenants_per_tract,\n",
    "    on='census_tract',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill NaN covenant counts with 0\n",
    "combined_data['covenant_count'] = combined_data['covenant_count'].fillna(0)\n",
    "\n",
    "# Basic Analysis\n",
    "print(\"\\nMerge Results:\")\n",
    "print(\"Total mortgage applications:\", len(combined_data))\n",
    "print(\"Applications in tracts with covenants:\", (combined_data['covenant_count'] > 0).sum())\n",
    "print(\"Unique tracts with covenants:\", combined_data[combined_data['covenant_count'] > 0]['census_tract'].nunique())\n",
    "\n",
    "# Calculate approval rates\n",
    "combined_data['was_approved'] = combined_data['action_taken'].isin([1, 2])\n",
    "covenant_areas = combined_data['covenant_count'] > 0\n",
    "\n",
    "print(\"\\nApproval Rates:\")\n",
    "print(\"Tracts with no covenants:\", \n",
    "      combined_data[~covenant_areas]['was_approved'].mean())\n",
    "print(\"Tracts with covenants:\", \n",
    "      combined_data[covenant_areas]['was_approved'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['activity_year', 'census_tract', 'derived_race', 'action_taken',\n",
       "       'loan_amount', 'property_value', 'income', 'interest_rate',\n",
       "       'tract_minority_population_percent', 'tract_to_msa_income_percentage',\n",
       "       'denial_reason-1', 'covenant_count', 'was_approved'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
